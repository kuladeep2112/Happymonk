{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import onnx\n",
        "from yolov5 import utils"
      ],
      "metadata": {
        "id": "VA9r0Smmf2bX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtxpJfUMloSb",
        "outputId": "8e423511-eeb3-4a07-a8b3-6ec261caff94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-48-g5f8054c Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 23.6/78.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "display = utils.notebook_init()  # checks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert to ONNX\n",
        "Select the model version and input size. Default: YOLOV6s (640x480)"
      ],
      "metadata": {
        "id": "PlAqR7PJmvTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov5\n",
        "!pip3 install onnx>=1.10.0\n",
        "model = 'yolov5s6' \n",
        "input_width = 640 \n",
        "input_height = 480 \n",
        "\n",
        "!python3 export.py --weights yolov5s6.pt --img {input_height} {input_width} --batch 1 --include \"onnx\" --simplify"
      ],
      "metadata": {
        "id": "60WjlWvFe5GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **helper.py function must be moved inside yolov5. Path to access helper.py will be yolov5/helper.py**"
      ],
      "metadata": {
        "id": "bILgjKJ-vfy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import onnxruntime\n",
        "\n",
        "from yolov5.helper import xywh2xyxy, nms, draw_detections\n",
        "\n",
        "\n",
        "class YOLOv5:\n",
        "\n",
        "    def __init__(self, path, conf_thres=0.7, iou_thres=0.5, official_nms=False):\n",
        "        self.conf_threshold = conf_thres\n",
        "        self.iou_threshold = iou_thres\n",
        "        self.official_nms = official_nms\n",
        "\n",
        "        # Initialize model\n",
        "        self.initialize_model(path)\n",
        "\n",
        "    def __call__(self, image):\n",
        "        return self.detect_objects(image)\n",
        "\n",
        "    def initialize_model(self, path):\n",
        "        self.session = onnxruntime.InferenceSession(path,\n",
        "                                                    providers=['CUDAExecutionProvider',\n",
        "                                                               'CPUExecutionProvider','CPUExecutionProvider'])\n",
        "        # Get model info\n",
        "        self.get_input_details()\n",
        "        self.get_output_details()\n",
        "\n",
        "        self.has_postprocess = 'score' in self.output_names or self.official_nms\n",
        "\n",
        "\n",
        "    def detect_objects(self, image):\n",
        "        input_tensor = self.prepare_input(image)\n",
        "\n",
        "        # Perform inference on the image\n",
        "        outputs = self.inference(input_tensor)\n",
        "\n",
        "        if self.has_postprocess:\n",
        "            self.boxes, self.scores, self.class_ids = self.parse_processed_output(outputs)\n",
        "\n",
        "        else:\n",
        "            # Process output data\n",
        "            self.boxes, self.scores, self.class_ids = self.process_output(outputs)\n",
        "\n",
        "        return self.boxes, self.scores, self.class_ids\n",
        "\n",
        "    def prepare_input(self, image):\n",
        "        self.img_height, self.img_width = image.shape[:2]\n",
        "\n",
        "        input_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Resize input image\n",
        "        input_img = cv2.resize(input_img, (self.input_width, self.input_height))\n",
        "\n",
        "        # Scale input pixel values to 0 to 1\n",
        "        input_img = input_img / 255.0\n",
        "        input_img = input_img.transpose(2, 0, 1)\n",
        "        input_tensor = input_img[np.newaxis, :, :, :].astype(np.float32)\n",
        "\n",
        "        return input_tensor\n",
        "\n",
        "\n",
        "    def inference(self, input_tensor):\n",
        "        start = time.perf_counter()\n",
        "        outputs = self.session.run(self.output_names, {self.input_names[0]: input_tensor})\n",
        "\n",
        "        print(f\"Inference time: {(time.perf_counter() - start)*1000:.2f} ms\")\n",
        "        return outputs\n",
        "\n",
        "    def process_output(self, output):\n",
        "        predictions = np.squeeze(output[0])\n",
        "\n",
        "        # Filter out object confidence scores below threshold\n",
        "        obj_conf = predictions[:, 4]\n",
        "        predictions = predictions[obj_conf > self.conf_threshold]\n",
        "        obj_conf = obj_conf[obj_conf > self.conf_threshold]\n",
        "\n",
        "        # Multiply class confidence with bounding box confidence\n",
        "        predictions[:, 5:] *= obj_conf[:, np.newaxis]\n",
        "\n",
        "        # Get the scores\n",
        "        scores = np.max(predictions[:, 5:], axis=1)\n",
        "\n",
        "        # Filter out the objects with a low score\n",
        "        predictions = predictions[scores > self.conf_threshold]\n",
        "        scores = scores[scores > self.conf_threshold]\n",
        "\n",
        "        if len(scores) == 0:\n",
        "            return [], [], []\n",
        "\n",
        "        # Get the class with the highest confidence\n",
        "        class_ids = np.argmax(predictions[:, 5:], axis=1)\n",
        "\n",
        "        # Get bounding boxes for each object\n",
        "        boxes = self.extract_boxes(predictions)\n",
        "\n",
        "        # Apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
        "        indices = nms(boxes, scores, self.iou_threshold)\n",
        "\n",
        "        return boxes[indices], scores[indices], class_ids[indices]\n",
        "\n",
        "    def parse_processed_output(self, outputs):\n",
        "\n",
        "        #Pinto's postprocessing is different from the official nms version\n",
        "        if self.official_nms:\n",
        "            scores = outputs[0][:,-1]\n",
        "            predictions = outputs[0][:, [0,5,1,2,3,4]]\n",
        "        else:\n",
        "            scores = np.squeeze(outputs[0], axis=1)\n",
        "            predictions = outputs[1]\n",
        "        # Filter out object scores below threshold\n",
        "        valid_scores = scores > self.conf_threshold\n",
        "        predictions = predictions[valid_scores, :]\n",
        "        scores = scores[valid_scores]\n",
        "\n",
        "        if len(scores) == 0:\n",
        "            return [], [], []\n",
        "\n",
        "        # Extract the boxes and class ids\n",
        "        # TODO: Separate based on batch number\n",
        "        batch_number = predictions[:, 0]\n",
        "        class_ids = predictions[:, 1].astype(int)\n",
        "        boxes = predictions[:, 2:]\n",
        "\n",
        "        # In postprocess, the x,y are the y,x\n",
        "        if not self.official_nms:\n",
        "            boxes = boxes[:, [1, 0, 3, 2]]\n",
        "\n",
        "        # Rescale boxes to original image dimensions\n",
        "        boxes = self.rescale_boxes(boxes)\n",
        "\n",
        "        return boxes, scores, class_ids\n",
        "\n",
        "    def extract_boxes(self, predictions):\n",
        "        # Extract boxes from predictions\n",
        "        boxes = predictions[:, :4]\n",
        "\n",
        "        # Scale boxes to original image dimensions\n",
        "        boxes = self.rescale_boxes(boxes)\n",
        "\n",
        "        # Convert boxes to xyxy format\n",
        "        boxes = xywh2xyxy(boxes)\n",
        "\n",
        "        return boxes\n",
        "\n",
        "    def rescale_boxes(self, boxes):\n",
        "\n",
        "        # Rescale boxes to original image dimensions\n",
        "        input_shape = np.array([self.input_width, self.input_height, self.input_width, self.input_height])\n",
        "        boxes = np.divide(boxes, input_shape, dtype=np.float32)\n",
        "        boxes *= np.array([self.img_width, self.img_height, self.img_width, self.img_height])\n",
        "        return boxes\n",
        "\n",
        "    def draw_detections(self, image, draw_scores=True, mask_alpha=0.4):\n",
        "\n",
        "        return draw_detections(image, self.boxes, self.scores,\n",
        "                               self.class_ids, mask_alpha)\n",
        "\n",
        "    def get_input_details(self):\n",
        "        model_inputs = self.session.get_inputs()\n",
        "        self.input_names = [model_inputs[i].name for i in range(len(model_inputs))]\n",
        "\n",
        "        self.input_shape = model_inputs[0].shape\n",
        "        self.input_height = self.input_shape[2]\n",
        "        self.input_width = self.input_shape[3]\n",
        "\n",
        "    def get_output_details(self):\n",
        "        model_outputs = self.session.get_outputs()\n",
        "        self.output_names = [model_outputs[i].name for i in range(len(model_outputs))]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    model_path = \"/content/yolov5/yolov5s6.onnx\"\n",
        "\n",
        "    # Initialize YOLOv7 object detector\n",
        "    yolov5_detector = YOLOv5(model_path, conf_thres=0.3, iou_thres=0.5)\n",
        "\n",
        "    # Initialize the webcam\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "    cv2.namedWindow(\"Detected Objects\", cv2.WINDOW_NORMAL)\n",
        "    while cap.isOpened():\n",
        "\n",
        "      # Read frame from the video\n",
        "      ret, frame = cap.read()\n",
        "\n",
        "      if not ret:\n",
        "          break\n",
        "\n",
        "      # Update object localizer\n",
        "      boxes, scores, class_ids = yolov5_detector(frame)\n",
        "\n",
        "      combined_img = yolov5_detector.draw_detections(frame)\n",
        "      cv2.imshow(\"Detected Objects\", combined_img)\n",
        "\n",
        "      # Press key q to stop\n",
        "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "          break\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1izCvC-qRSM",
        "outputId": "2007c031-a7d2-4fca-faf7-2e888a835632"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference time: 294.53 ms\n"
          ]
        }
      ]
    }
  ]
}